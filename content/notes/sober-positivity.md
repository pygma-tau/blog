---
title: On Sober Positivity
author: Yudhister Kumar
date: 2025-10-18
draft: true
---

[*particularly draft-like and not rigorous*]

I have a tendency to think soberly about bad things and "like a drunkard" about good ones. For instance:

- When I was 16, I thought a lot about borazane as a hydrogen store. My thought process was roughly: "energy is important! clean energy is important! in the limit hydrogen-based energy mechanisms will become ubiquitous, so I should work on enabling technologies for that now!" 
- My first proper job was working at a philosophy think-tank aimed at reducing the risk of astronomical suffering. I spent a significant amount of time quantifying the implications of various ethical theories & taxonomizing superintelligent conflict regimes to identify which posed the most risk and which were plausibly tractable. 

To put it differently, my two motivational structures were:
- "I wish to summon more of this into the world because of the specific way it vibes with reality" 
- and "radically minimize pain." 

This made a lot of sense to 2023-Yudhi, who didn't really think that more of a good thing was good! But 2025-Yudhi is surprisingly normal and likes things and thinks the things he likes are good and is perhaps more sympathetic to naive hedonic utilitarianism then he used to be. 

So. What do? 

One obvious thing to do: figure out what is good, quantify it, see which actions maximize the expected good, and see what prescriptive diffs this algorithm generates.  There are many, many criticisms you can level at this plan of action, not least because as stated this is *incredibly* underspecified, but I want to address two, one fake and one real:

[1] It sure seems much harder to figure out what's Good compared to what's Bad, so maybe we should just focus on what we know is worthwhile (anti-Bad activity), and not act on our moral uncertainty too much (pro-Good activity).

[2] There is so much suffering in the world! Even from a pro-Good stance, you should still be mostly engaging in anti-Bad activity! 

[1] is defeatist, and while there are probably reasonable arguments to be made for non-action in the face of moral uncertainty I don't really think they stand up to intense scrutiny. And even if they did, I expect they would route through [2] (in the sense that the only robustly pro-Good actions you could come up with are still worse than the anti-Bad ones).

[2] is a fundamentally a claim about the world. It should be evaluated as one. Evaluating it is hard! You probably have to think about [astronomical waste considerations](https://nickbostrom.com/papers/astronomical-waste/), [grabby aliens](https://grabbyaliens.com/), the [Fermi paradox](https://arxiv.org/abs/1806.02404), the [Great Filter](https://mason.gmu.edu/~rhanson/greatfilter.html), [wild animal suffering](https://en.wikipedia.org/wiki/Wild_animal_suffering), [evidential cooperation in large worlds](https://longtermrisk.org/multiverse-wide-cooperation-via-correlated-decision-making/), many metaethical problems we haven't come across yet, many scenarios that I'm not aware of, many more normal considerations that don't involve zany decision theories or superintelligences or aliens to check that you're not missing present occurrences that are of comparable effective magnitude. 

I am not claiming to resolve [2] now. But when I try and think about it seriously, I don't really find any of the "astronomical waste"-esque arguments particularly compelling on a S1 level. *Can't you just argue that AI safety is more important because the unaligned superintelligence wouldn't make those lives worth living at all? Can't you just take every one of the arguments for preserving the long-term future and say, well, we live in the most pivotal time for ensuring that human values propagate, so you should be minimizing risk as much as possible?*

A version that *is* emotionally compelling to me:

*Look around you. The world is so strange. Civilization is so strange. Do you really think that the society you live in is anti-fragile? Do you really think our presence in the here and now is Overdetermined, just a byproduct of 2% YoY real GDP growth? Do you really think that those peculiarities you enjoy will persist and multiply by default?*

*Almost everything you care about was built by someone who cared deeply. In the face of profoundly natural antagonism. We escaped the Malthusian trap by raising our carrying capacity through sheer grit; our society stability rests on a flimsy foundation of our greatest minds throwing themselves into meat-grinders to generate technological innovations to eke out another quarter-centipoint of growth. And you want to control one of the only hopes we have of preserving this, by muzzling innovation and redirecting our efforts away from progress?*

I wish we had a better sense of the fragility of human value; I wish we better understood the importance of intangibles in society. This post was neither particularly positive nor sober, but I do think I have a deficiency in this realm. 





