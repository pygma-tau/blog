<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
        <title>Notes - Page 3</title>
    
    <link rel="stylesheet" href="https://yudhister.me/style.css">
    <!-- MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://yudhister.me/js/footnotes.js"></script>
    
    <script src="https://yudhister.me/js/filter.js" defer></script>
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-TKY9S092B5"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-TKY9S092B5');
    </script>
    <script>
		window.MathJax = {
		  tex: {
			inlineMath: [['$','$'], ['\\(','\\)']],
			displayMath: [ ['$$','$$'], ["\\[","\\]"], ]
		  },
		  startup: {
			ready: () => {
					// Function to iterate over all pre and code elements
					// if they contain TeX/LaTeX code for maths as defined
					// by the markers in tex settings above then copy their
					// textContent before them and remove the element from
					// the DOM.

					// get pre and code elements
					var prelist = document.getElementsByTagName("pre");
					var codelist = document.getElementsByTagName("code");
					// get delimiters for inline and display math
					var inline = MathJax.config.tex.inlineMath;
					var display = MathJax.config.tex.displayMath;
					// start building  a RegExp for each of these math types
					var inlineRegexList = [];
					var displayRegexList =[];
					for(i=0;i<inline.length;i++) {
						// https://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
						delimLEsc = inline[i][0].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
						//alert(delimLEsc);
						delimREsc = inline[i][1].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
						inlineRegexList.push("("+delimLEsc+")((.|[\\r\\n\\t])*?)("+delimREsc+")");
					};
					for(i=0;i<display.length;i++) {
						// https://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
						delimLEsc = display[i][0].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
						//alert(delimLEsc);
						delimREsc = display[i][1].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
						displayRegexList.push("("+delimLEsc+")((.|[\\r\\n\\t])*?)("+delimREsc+")");
					};
					inlineRegExp = new RegExp(inlineRegexList.join("|"));
					displayRegExp = new RegExp(displayRegexList.join("|"));

					// iterate over pre elements applying RegExp
					// iterate "backwards" as we are removing elements!
					for (i=prelist.length; i>0; i--) {
						if(displayRegExp.test(prelist[i-1].textContent)) {
							var t = document.createTextNode(prelist[i-1].textContent);
							prelist[i-1].parentNode.insertBefore(t,prelist[i-1]);
							prelist[i-1].parentNode.removeChild(prelist[i-1]);
						}
					}
					// iterate over code elements applying RegExp
					// iterate "backwards" as we are removing elements!
					for (i=codelist.length; i>0; i--) {
						if(inlineRegExp.test(codelist[i-1].textContent)) {
							var t = document.createTextNode(codelist[i-1].textContent);
							codelist[i-1].parentNode.insertBefore(t,codelist[i-1]);
							codelist[i-1].parentNode.removeChild(codelist[i-1]);
						}
					}
			  // Now process the page in MathJax
			  MathJax.startup.defaultReady();
			}
		  }
		};
		</script>
		<script type="text/javascript" id="MathJax-script" async
		  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
		</script>
</head>
<body>
	<nav>
        <ul>
            <li>[<a href="/">Home</a>]</li>
            <li>[<a href="/about">About</a>]</li>
            <li>[<a href="/notes">Notes</a>]</li>
			<li>[<a href="/shelf">Shelf</a>]</li>
			<!-- <li>[<a href="/cities">Cities</a>]</li> -->
			<!-- <li>[<a href="/heroes">Heroes</a>]</li> -->
			<li>[<a href="mailto:yudhister.j.kumar@gmail.com">Email</a>]</li>
			<li>[<a href="/atom.xml">RSS</a>]</li>
        </ul>
    </nav>
    <main>
        <h1>Notes</h1>
        
        

        
        <p class="filter-toggle-wrapper">[<a href="#" id="filter-toggle">show all</a>]</p>
        

        
            
            
                
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/qol/">surprisingly high-leverage QoL improvements</a></h2>
                            <time datetime="2026-01-03">January 03, 2026</time>
                        </header>
                        <div class="post-content">
                            <p>[YMMV, reverse all advice given, what works for me may not work for thee, <em>caveat emptor</em>, etc.]</p>
<ul>
<li>consuming 2-3 servings of fish 5-6 days out of the week. ~essentially stopped major depressive periods c. September 2025. have not extensively tested reducing # of servings/day, but dropping to 3-4 days/wk seems to work about as well</li>
<li>waking up prior to sunrise. the subjective length of the day increases when I'm awake for mornings! and for some reason or other I can only get serious work done pre-noon or after sunset. i'm also consistently happy every time i see the sunrise</li>
<li>acquiring an e-bike. SF is ridiculously bikeable, and e-bike rentals are $100-150/wk. almost always deeply enjoyable, esp. when the assist makes climbing hills less painful</li>
<li>cordless waterflosser. ~substitutes for normal floss (e.g. frequency reduced to &lt;1wk), much more convenient than corded ones,</li>
<li>learning to be actively intentional about what music I listen to.</li>
<li>"make anki flashcard" as tool-call; removes anxiety about forgetting. can range from complicated image to quote to fuzzy concept you remind yourself to revisit to remembering the conditions under which certain people act in certain ways (including yourself!) to update your blindspots.</li>
<li>unlimited zotero storage + daylight computer. high-refresh rate on a yellow-backlit tablet is incredibly soothing &amp; perfect to fall asleep to</li>
<li>bilevel notebooks. one relatively fancy, moleskin-esque bullet journal for condensing the thoughts of a given day; one spiral-bound, A4 sized to record jottings. this is useful because (1) can be used as reference without forcing something to legibilize too early, and also sometimes you want to vocalize thoughts without necessarily reifying / endorsing them (they can stay in (2)!).</li>
</ul>
<p>will update as I remember. excluded are unsurprisingly high-leverage QoL improvements</p>

                        </div>
                    </article>
                    
                        <hr class="post-separator">
                    
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/sl5-literacy/">[draft] SL5 Literacy</a></h2>
                            <time datetime="2026-01-02">January 02, 2026</time>
                        </header>
                        <div class="post-content">
                            <p>In 2024, RAND released <a href="https://www.rand.org/pubs/research_reports/RRA2849-1.html">a paper</a> aiming to develop security standards for "preventing [the] theft and misuse of frontier models." It introduced the "security level" framework for the first time, where each level SL1-SL5 is characterized by the necessary security properties a system must possess to resist threats from an attacker of a given cybercapacity. Examples:</p>
<ul>
<li>
<p>SL2: "a system that can likely thwart most professional opportunistic efforts by attackers that execute moderate-effort or nontargeted attacks." At this level, frontier model weights should be exclusively stored on company servers, copies should only be shared through encrypted channels, and duplicates are monitored closely. Google DeepMind trained Gemini 2.5 at this level.</p>
</li>
<li>
<p>SL4: "A system that can likely thwart most standard operations by leading cyber-capable institutions.<sup class="footnote-reference"><a href="#1">1</a></sup>" Now we're talking about source-code auditing all hardware used, supply chain validation, "specialized hardware for all external interfaces", "occasional employee integrity testing", in-house ability to discover zero-days, confidential computing where possible, and so on. This level of security is comparable to AWS or Google.</p>
</li>
<li>
<p>SL5: "A system that could plausibly be claimed to thwart most top-priority operations by the top cyber-capable institutions." Requires trusted execution environments on GPUs/TPUs, robust hardware security against side-channel attacks, completely secure supply chains, and quite stringent organizational practices. <strong>SL5 systems do not exist and cannot exist with currently public technology.</strong> If OpenAI had SL5-level security, then it would be able to resist China putting a significant amount of national resources into stealing GPT-7.</p>
</li>
</ul>
<p>At least to my ears, developing SL5 standards is abuzz in the technical governance crowd. I'm not even a cybersecurity amateur, so I didn't really know what to make of it. Why is it so hard? What are the major obstacles to implementing even SL4 in practice? From a purely technical perspective, what sorts of technology needs to be developed?</p>
<p>IFP released <a href="https://ifp.org/a-sprint-toward-security-level-5/">a report</a> roadmapping "a sprint towards" SL5. I found the specifics lackluster. They break down necessary improvements into five areas: "hardware, software, people, facilities, and integrated security operations." Hardware improvements: funding anti-tamper tech, mapping supply chains, using DARPA to fund next-gen GPU security solutions. Software improvements: <a href="https://www.darpa.mil/research/programs/translating-all-c-to-rust">literally translate all your C to Rust</a> and invent formal verification protocols with good UX. Very helpful.</p>
<p>The SL5 Task Force released <a href="https://sl5.org/pdfs/SL5_NOVEL-RECOMMENDATIONS.pdf">an SL5 blueprint</a> in November 2025. It's five separate memos stapled together: Machine Security, Network Security, Personnel Security, Physical Security, and Supply Chain Security.<sup class="footnote-reference"><a href="#2">2</a></sup> While I can't judge quality, I enjoyed the specificity.</p>
<p>Insightful:</p>
<blockquote>
<p>Whereas SL4 can plausibly be reached incrementally, <em>SL5 can likely only or at least most quickly and cheaply be reached by a radical reduction in the hardware and software stack that is trusted</em>, as well as a reduction of the volume of code that interfaces with critical components, or is necessary for critical actions (this term for instance includes any processes touching model weights, hardware and software that trust is deferred to, etc.)</p>
</blockquote>
<p>Although this is mentioned in the context of supply chains, it's likely true for all other areas as well. Supply chains are insecure by default, especially to a nation-state actor, because economic incentives for efficiency (and subsequently diversity, because of gains from trade) drastically increase the surface area of attack. The surface area remains large at other parts of the stack as well. Modern ML training frameworks are sprawling, and no one invented good trusted execution environments for chips that serve models. One of the reasons why AWS &amp; Google are so secure is because trust is distributed among personel such that there are very few singular points of failure, and that sensitive information is carefully sandboxed.</p>
<blockquote>
<p>Access to sensitive resources should be provided only through safe, narrow APIs that perform specific operations (e.g., fine-tuning, quantization, inference) rather than allowing direct resource manipulation. This enables critical operations to run with a minimal software stack containing only essential, hardened components, while the broader R&amp;D ecosystem—with its necessary but less-trusted dependencies—operates in isolated environments without direct access.</p>
</blockquote>
<p>The set {fine-tuning, quantization, inference} allows an end-user quite a lot of behavioral access to the model! If logits or similar are exposed, training a student model is not insane? Managing such API access in a research org also seems quite complicated, but maybe tech companies have the organizational chutzpah to pull this off without completely sacrificing their progress engine on the altar.</p>
<blockquote>
<p>AI accelerators have historically lacked critical security features, leaving model weights and sensitive data vulnerable to extraction. One example is earlier generations of accelerators (e.g., TPU v3 and v4) that typically lack native link-layer encryption for ICI. For instance, TPU v4 relies on Optical Circuit Switches (OCS) to create "air gapped network isolation" between customers rather than encrypting the data on the interconnects. Consequently, model weights and other sensitive data are transmitted between accelerators in plaintext. These could potentially be intercepted directly from the cables in data centers without any need to interact with the chip itself.</p>
</blockquote>
<p>Weights have to be protected at the hardware level because fully homomorphic encryption is not mature enough to allow computations to be done on encrypted structures at the level of complexity models have. However, clusters and GPUs have not been designed to meet this standard. From a cluster perspective, protecting weights is difficult because weights are transferred quite a lot to/fron without encryption. From a chip perspective, making TEEs is a tall order.</p>
<p>[this is unfinished, need to include more examples, but meets the blog post bar]</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>"Operations roughly less capable than or comparable to 100 individuals who have experience in a variety of relevant professions [...] spending a year with a total budget of up to $10 million on the specific operation, with vast infrastructure and access to state resources..."</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>Compare to IFP's categorization. (They're the same).</p>
</div>

                        </div>
                    </article>
                    
                        <hr class="post-separator">
                    
                
                    <article class="post" data-good="true">
                        <header>
                            <h2><a href="https://yudhister.me/2025/">2025 In Review</a></h2>
                            <time datetime="2026-01-01">January 01, 2026</time>
                        </header>
                        <div class="post-content">
                            <p>2025 was odd.</p>
<p>It was the best of times. I am happier today than I ever have been. I learned gorgeous and utilitarian concepts alike; I crossed the employability threshold and work with incredible comrades; I live in a home with some of my favorite people on the planet. I'll be 20 soon and the future is bright.</p>
<p>It was the worst of times. Mired in a haze of hopelessness and confusion. I spent months and months in pain and as an insomniac; I was cripplingly sick for half a year. For the first time, I have regrets. Proper ones, ones that I'll never forget as long as I live.</p>
<p>It is good to have lived, maybe. I never want to let the preconditions for this year exist again.</p>
<h3>Ideas</h3>
<p>Spent the first half of the year thinking about how to think about neural networks. Mean-field approaches to spin glasses, nonequilibrium QFT, KL bounds via stochastic coupling, depth-width tradeoffs, representational capacity (benchmarked by circuit complexity classes), singular learning theory, computational mechanics, variational reformulations of RL. Some of it was misguided, much was interesting.</p>
<p>Vaintrob et. al. have been pursuing a QFT-inspired approach to interpretability. It's really cool, and I'm excited to (hopefully) see their empirical work come out this year. Dmitry's post on <a href="https://www.lesswrong.com/posts/M2bs6xCbmc79nwr8j/dmitry-vaintrob-s-shortform?commentId=A8Ziwhts35dgqbz52">"SLT as a thermodynamic theory of Bayesian learning, but not the thermodynamic theory of Bayesian learning"</a> is one of the most interesting I've read this year.</p>
<p>Read Debreu on microeconomics. Yasheng Huang on Chinese capitalism. Ran a Land-focused reading group running through Bateson, Hegel, analytical Marxism, Kant, and Land himself. Finnegans Wake and EGA are both prime examples of <a href="https://www.yudhister.me/idiolects/">idiolects</a>. Yuxi Liu has a great blog. Read the formalization of Chomsky's syntax-semantics theory while recovering from surgery. Thought about chromosomal selection and inducing meiosis in oogonia at the Reproductive Frontiers conference.</p>
<p>Summer rolled around, I was briefly back to 95% capacity, and I was contracting for ILIAD (the org) &amp; planning to intern at Softmax. Making an open problems list for ODYSSEY (the conference) was enlightening. Curation is very, very difficult! Making sure that your theoretical brainchildren touch grass is almost as hard!</p>
<p>Softmax forced me to properly learn to code. Programming is very different when done collaboratively in a shared codebase, doubly so when one's research code must be written quickly, efficiently, and in a manner interpretable to others. I'm glad I got to think about multi-agent RL and what makes good management good.</p>
<p>My thoughts for the rest of the year were less legible. Tiling is an important problem. Formalizing it is hard. Acausal coalitional structure is confusing. Astronomical waste may or may not be an issue. Transpiling meta-ethical frameworks is hard. Biosingularitarian governance is hard. Is macrohistory determined by the nucleation stages of technological development or by deep convergent pressures leading to certain outcomes? How would we know?</p>
<p>At SI, we think about meta-learning and recurrence, among other things. Attempting to understand these deeply has been fruitful. A Berkeley professor ran a seminar on Adorno and poetry with a wonderful reading list. Semiotic physics is confusing, but Owain Evans has some good frames. Evolutionary optimization is surprisingly sample-efficient. Training deep neural networks is hard. Post-AGI futures are confusing and hard to think about, but Korinek has good frames. Weight-sparse models are deeply interesting.</p>
<p>In 2026, I want to drastically shorten my map-territory feedback loops. Intellectually, my greatest flaw this year was not investing in it. Admittedly, I probably did not have the energy for it. Luckily, this year is shaping up to be different.</p>
<h3>Some Randomly Sampled Moments</h3>
<p>[redacted]</p>
<h3> People </h3>
<p>[redacted]</p>
<h3>Miscellanea</h3> 
<p>[TBD]</p>

                        </div>
                    </article>
                    
                        <hr class="post-separator">
                    
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/rights-of-the-leviathan/">commentary on Leviathan rights</a></h2>
                            <time datetime="2025-12-07">December 07, 2025</time>
                        </header>
                        <div class="post-content">
                            <p>[<a href="https://www.gutenberg.org/cache/epub/3207/pg3207-images.html">see Leviathan XVII</a>]</p>
<p>[1]. Revolution is illegitimate. Sovereign power is derived from the one-time consent of the governed. Not only is it illegitimate to attempt a contractual renegotiation, it is unjust; doubly so if done in the name of God.</p>
<p>[2]. Sovereigns do not contract with the People. Such a construction is structurally incoherent. Thus sovereign authority cannot be forefeited, and regardless the state maintains a monopoly on violence.</p>
<p>[3]. Protest is illegitimate.</p>
<p>[4]. A subject cannot justly critique a sovereign's actions, as partaking in the Covenant consequently places the responsibility for the sovereign's actions on the subject.</p>
<p>[5]. Sovereigns are unpunishable.</p>
<p>[6]. Matters of peace and defence are solely the purview of the sovereign, domestic or otherwise. Education of the populace likewise.</p>
<p>[7]. Law-making is the sole purview of the sovereign, with the aim of ensuring the consituency acts peaceably and justly.</p>
<p>[8]. The power to judge "controversy", be it legal or factual, belongs to the sovereign.</p>
<p>[9]. The sovereign has the sole authority to make war and peace.</p>
<p>[10]. The sovereign has the sole authority to staff an executive.</p>
<p>[11]. The sovereign may reward or punish his subjects as he sees fit.</p>
<p>[12]. The sovereign maintains a monopoly on status signifiers and honors conferred on subjects.</p>

                        </div>
                    </article>
                    
                        <hr class="post-separator">
                    
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/criticality-in-value-formation/">Criticality in Value Formation</a></h2>
                            <time datetime="2025-11-22">November 22, 2025</time>
                        </header>
                        <div class="post-content">
                            <p>underspecified thesis: qualitative differences in phenomenal effects are primarily determined by the conditions under which nucleation occurs; the environmental conditions of phase transitions are the primary determinants of the long-run behavior.</p>
<ul>
<li>examples: <a href="https://www.nature.com/articles/srep10101">prion diseases</a>, <a href="https://www.pnas.org/doi/10.1073/pnas.0437744100">ritonavir</a>. cases where a structure exhibits polymorphism &amp; the particular polymorph propagated is sensitive to initial conditions</li>
<li>counterexamples: error-correcting codes (robust to perturbation), some chaotic systems (no 'qualitatively different' basins in double pendulum behavior), mutational reproductive success (more fit mutations will propagate more widely, this is not generally determined by the time at which the mutation appears in the population)</li>
</ul>
<p>is this true for value formation? some cases:</p>
<ul>
<li>broadly, "developmental interpretability," insofar as one is interested in characterizing the stage-wise development of a neural network's policy. the SLT thesis as pursued by Timaeus (see <a href="https://timaeus.co/research/2025-10-05-influence-dynamics">Influence Dynamics and Stagewise Data Attribution</a>, <a href="https://timaeus.co/research/2025-08-01-embryology-of-a-language-model">Embryology of a Language Model</a>, <a href="https://timaeus.co/research/2025-04-25-modes">Modes of Sequence Models and Learning Coefficients</a>) falls in this category, as does characterizing the inductive bias of SGD, expanding the SLT story to encompass RL, attempts to link algorithmic information theory to modern training dynamics, the "neural nets as QFTs" perspective (see <a href="https://arxiv.org/abs/2310.03789">Grokking as a First Order Phase Transition in Two Layer Networks</a>).
<ul>
<li>pros: empirical work on actual neural nets we can train and try to interpret!</li>
<li>cons: much work involves toy models and doesn't address the "what are values" question; there's a streetlighting effect where we find structure that we look for &amp; ignore the parts of the network which look "random" from this perspective</li>
<li>meta-con of all? the theoretical interp work being somewhat predicated on the thesis that the algorithmic structure of the learned policy is determined by phase transitions in some thermodynamic-ish measurables of the network
<ul>
<li>comp-mech/Simplex not like this</li>
</ul>
</li>
<li>success of these agendas should be evidence in favor of the thesis</li>
</ul>
</li>
<li>sharp-left turn discourse
<ul>
<li>existence of sharp-left turns implies criticality in value formation (not polymorphism)</li>
<li>my summary of <a href="https://www.lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization">the original argument</a>:
<ul>
<li>"being generally capable" is instrumentally useful in a way that "being aligned" is not (also my understanding of the corrigibility is anti-natural argument), so there exists a strong attractor towards capability improvement that does not exist for alignment, alignment &amp; capabilities are not aligned in the limit thus capabilities generalize farther &amp; faster than alignment so your alignment breaks</li>
</ul>
</li>
<li>i don't quite understand the arguments or counterarguments or really the arguments for why corrigibility is anti-natural?</li>
<li>one way I want to concretize this is saying something about the stability of a logical inductor's value of statements which refer to itself (goals are 'just' beliefs about future actions, values are 'just' persistent goals)
<ul>
<li>LIs have Introspection (4.11) and Self-Trust (4.12) which makes their behavior nice in the limit</li>
<li>plausibly you'd want to study beliefs in a game-like setting, either with information revelation over agent preferences or environment state, and see what happens?</li>
</ul>
</li>
</ul>
</li>
<li>humans
<ul>
<li>trauma / philosophy / psychosis / abnormal psychological effects can induce extreme value shifts. this does not seem to be accompanied by an overall increase in individual performance</li>
<li>humans raised in a slightly abnormal environment are pretty normal. humans raised outside of society are not very normal.</li>
<li>the 'philosopher AI concern' comes from a belief that at some point the agents will be able to arbitrarily reflect &amp; decide what their values should be. i feel like consequentialist agents at time $t_0$ are incentivized not to let this happen at time $t_1 &gt; t_0.$</li>
<li>in particular humans cannot arbitrarily intervene on their values very well</li>
</ul>
</li>
</ul>

                        </div>
                    </article>
                    
                

                
                <nav class="pagination">
                    
                        <a class="previous" href="https://yudhister.me/notes/page/2/">‹ Previous</a>
                    
                    <span class="page-number">Page 3 of 11</span>
                    
                        <a class="next" href="https://yudhister.me/notes/page/4/">Next ›</a>
                    
                </nav>

            
        
    </main>
</body>
</html>
