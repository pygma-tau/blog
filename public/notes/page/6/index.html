<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
        <title>Notes - Page 6</title>
    
    <link rel="stylesheet" href="https://yudhister.me/style.css">
    <!-- MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://yudhister.me/js/footnotes.js"></script>
    
    <script src="https://yudhister.me/js/filter.js" defer></script>
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-TKY9S092B5"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-TKY9S092B5');
    </script>
    <script>
		window.MathJax = {
		  tex: {
			inlineMath: [['$','$'], ['\\(','\\)']],
			displayMath: [ ['$$','$$'], ["\\[","\\]"], ]
		  },
		  startup: {
			ready: () => {
					// Function to iterate over all pre and code elements
					// if they contain TeX/LaTeX code for maths as defined
					// by the markers in tex settings above then copy their
					// textContent before them and remove the element from
					// the DOM.

					// get pre and code elements
					var prelist = document.getElementsByTagName("pre");
					var codelist = document.getElementsByTagName("code");
					// get delimiters for inline and display math
					var inline = MathJax.config.tex.inlineMath;
					var display = MathJax.config.tex.displayMath;
					// start building  a RegExp for each of these math types
					var inlineRegexList = [];
					var displayRegexList =[];
					for(i=0;i<inline.length;i++) {
						// https://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
						delimLEsc = inline[i][0].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
						//alert(delimLEsc);
						delimREsc = inline[i][1].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
						inlineRegexList.push("("+delimLEsc+")((.|[\\r\\n\\t])*?)("+delimREsc+")");
					};
					for(i=0;i<display.length;i++) {
						// https://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
						delimLEsc = display[i][0].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
						//alert(delimLEsc);
						delimREsc = display[i][1].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
						displayRegexList.push("("+delimLEsc+")((.|[\\r\\n\\t])*?)("+delimREsc+")");
					};
					inlineRegExp = new RegExp(inlineRegexList.join("|"));
					displayRegExp = new RegExp(displayRegexList.join("|"));

					// iterate over pre elements applying RegExp
					// iterate "backwards" as we are removing elements!
					for (i=prelist.length; i>0; i--) {
						if(displayRegExp.test(prelist[i-1].textContent)) {
							var t = document.createTextNode(prelist[i-1].textContent);
							prelist[i-1].parentNode.insertBefore(t,prelist[i-1]);
							prelist[i-1].parentNode.removeChild(prelist[i-1]);
						}
					}
					// iterate over code elements applying RegExp
					// iterate "backwards" as we are removing elements!
					for (i=codelist.length; i>0; i--) {
						if(inlineRegExp.test(codelist[i-1].textContent)) {
							var t = document.createTextNode(codelist[i-1].textContent);
							codelist[i-1].parentNode.insertBefore(t,codelist[i-1]);
							codelist[i-1].parentNode.removeChild(codelist[i-1]);
						}
					}
			  // Now process the page in MathJax
			  MathJax.startup.defaultReady();
			}
		  }
		};
		</script>
		<script type="text/javascript" id="MathJax-script" async
		  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
		</script>
</head>
<body>
	<nav>
        <ul>
            <li>[<a href="/">Home</a>]</li>
            <li>[<a href="/about">About</a>]</li>
            <li>[<a href="/notes">Notes</a>]</li>
			<li>[<a href="/shelf">Shelf</a>]</li>
			<!-- <li>[<a href="/cities">Cities</a>]</li> -->
			<!-- <li>[<a href="/heroes">Heroes</a>]</li> -->
			<li>[<a href="mailto:yudhister.j.kumar@gmail.com">Email</a>]</li>
			<li>[<a href="/atom.xml">RSS</a>]</li>
        </ul>
    </nav>
    <main>
        <h1>Notes</h1>
        
        

        
        <p class="filter-toggle-wrapper">[<a href="#" id="filter-toggle">show all</a>]</p>
        

        
            
            
                
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/diffusion-roundup/">Diffusion Roundup</a></h2>
                            <time datetime="2025-09-24">September 24, 2025</time>
                        </header>
                        <div class="post-content">
                            <p>[1] <strong>Diffusion models seem to outperform traditional autoregressive models in the large data limit on token-prediction tasks.</strong> <sup class="footnote-reference"><a href="#1">1</a></sup> Autoregressive models are still superior in the low-data/compute-limited regime, and the threshold at which diffusion models become optimal follows a power-law in the dataset size (typically exceeding the Chinchilla threshold by a large margin).<sup class="footnote-reference"><a href="#2">2</a></sup> Diffusion models also see performance gains under “trivial” data augmentation methods for far longer than autoregressive models (e.g. reordering tokens), and this is plausibly because the generation method is fundamentally non-causal? (Much of the performance gap can be recovered by implementing similar data augmentation methods in the AR case, but it’s unclear if this scales to tasks that require “cognition” in the human sense of the word). Not entirely clear how this translates to better performance on real-world tasks in the data-limited regime; it could be that the compute scaling necessary is simply prohibitive, and it could also be that the implicit curriculum afforded by the de-noising process is simply insufficient at providing reasonable enough signal on difficult tasks.</p>
<p>[2] <strong>Diffusion in-practice probably has the circuit complexity depth constraints of an attention-based transformer.</strong> In the last few years, we’ve seen literature essentially claiming that attention in-practice is limited to modeling circuits in the class TC0 (polynomial width, constant depth Boolean circuit family)<sup class="footnote-reference"><a href="#3">3</a></sup> Adding chain-of-thought ~roughly increases this to NC1 (although there are some subtleties involving the lack of robustness to input-ordering).<sup class="footnote-reference"><a href="#4">4</a></sup> There are reasons to expect difficult problems, especially the sorts encountered in long-horizon RL, to require architectures that can internally simulate deep computation. These architectures have been recurrent thus far. However, recurrent architectures fail to adequately leverage the compute parallelism offered by GPUs and have many, many issues with unstable training dynamics, so scaling transformers is a better option. It’s probably not the case that diffusion models can prove an adequate replacement here, but it’s interesting that <a href="https://arxiv.org/abs/2507.12469">a diffusion process with no constraints imposed by a score function can theoretically simulate any Turing-complete process, but when perfectly matching a score function still has the limitations of a TC0 representation</a>. Results in the approximate regime pending.<sup class="footnote-reference"><a href="#5">5</a></sup></p>
<p>[3] <strong>Diffusion is (kind of) spectral autoregression.</strong><sup class="footnote-reference"><a href="#6">6</a></sup> There are <a href="https://sander.ai/2024/09/02/spectral-autoregression.html">two</a> <a href="https://www.fabianfalck.com/posts/spectralauto/">brilliant</a> blog-posts on the subject, cumulatively arguing that DDPM has an inductive bias to generating low-frequency features before high-frequency features (in Fourier space; hence the name) but this is not necessarily true of all possible diffusion models (changing the model’s noising schedule to be frequency-agnostic doesn’t degrade performance on CIFAR10 and similar datasets, but not all noising schedules achieve the same performance!). How much does this matter for text-data domains? Audio? Video? Are there correspondences we can make between distributional structure and optimal noising schedules? In algorithmic cases, what does this mean?</p>
<p>I primarily find diffusion models interesting from a theoretical perspective, given that the corresponding SDE literature is rich and there are (potentially) deep connections to be made to modern ML. In particular, I expect we can better understand what feature orderings are optimal, which properties of distributions make them learnable, how much an inductive bias is a property of the model architecture vs. optimization algorithm or other factors, and to what extent recurrence can be represented with parallel architectures. This post should not be taken as definitive; it has not been edited and I welcome feedback.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>This section is summarizing the paper <a href="https://arxiv.org/abs/2507.15857">Diffusion Beats Autoregression in Data-Constrained Settings</a>.</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>The metric the authors use is “number of unique tokens”—which is quite strange, given that the vocab size of a model is typically quite limited, and they mention training a 2.3B parameter diffusion model on a 500M unique token dataset. Perhaps they mean just the token size of a dataset with no repeated entries?</p>
</div>
<div class="footnote-definition" id="3"><sup class="footnote-definition-label">3</sup>
<p>See <a href="https://arxiv.org/abs/2207.00729">The Parallelism Tradeoff: Limitations of Log-Precision Transformers</a>, <a href="https://arxiv.org/abs/2402.09268">Transformers, parallel computation, and logarithmic depth</a>, and <a href="https://arxiv.org/abs/2412.02975">Theoretical limitations of multi-layer Transformer</a>.</p>
</div>
<div class="footnote-definition" id="4"><sup class="footnote-definition-label">4</sup>
<p>See <a href="https://arxiv.org/abs/2402.12875">Chain of Thought Empowers Transformers to Solve Inherently Serial Problems</a>. CoT/neuralese introducing “effective recurrence” into modern models seems to be important for timeline modeling.</p>
</div>
<div class="footnote-definition" id="5"><sup class="footnote-definition-label">5</sup>
<p>Reach out if you have thoughts!</p>
</div>
<div class="footnote-definition" id="6"><sup class="footnote-definition-label">6</sup>
<p>See A Fourier Space Perspective on Diffusion Models.</p>
</div>

                        </div>
                    </article>
                    
                        <hr class="post-separator">
                    
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/2025-08-20/">Linear Contracts Are Optimally Robust</a></h2>
                            <time datetime="2025-08-20">August 20, 2025</time>
                        </header>
                        <div class="post-content">
                            <p><em>nb: attempting a daily posting cadence. adjust quality priors accordingly</em></p>
<p>Consider the following game:</p>
<ol>
<li>Alice offers a contract $w: \mathcal{Y} \to \mathbb{R}^+$ to Bob.</li>
<li>Bob, knowing his compact action space over lotteries $\mathcal{A} \subseteq \Delta (\mathcal{Y}) \times \mathbb{R}^+,$ chooses action $(F,c) \in \mathcal{A},$</li>
<li>The output $y \sim F$ is realized (sampling from the lottery chosen)</li>
<li>Alice receives $y - w(y)$ payoff; Bob receives $w(y) - c$ payoff.</li>
</ol>
<p>Importantly, Alice receives limited information about Bob's action space (interchangeable with "technology"). What is the optimal contract Alice should give Bob, if she wants to maximize her worst case outcome? (We assume Alice and Bob are rational actors: their dynamics will be given shortly). This is an identical problem to studying the structure of the optimal $w$ in this scenario.</p>
<p><a href="file:///Users/yudhister/Zotero%20ysjk/storage/QX73679W/Carroll%20-%202015%20-%20Robustness%20and%20Linear%20Contracts.pdf">[Car15]</a><sup class="footnote-reference"><a href="#1">1</a></sup> proves that the optimal $w$ is linear, subject to the following assumptions: $\mathcal{Y} \subset \mathbb{R}^+,$ $\mathcal{A}$ must be compact; Alice (the "principal") knows $\mathcal{A}_0 \subseteq \mathcal{A}$ possible actions for Bob (the "agent") such that there exists $(F,c) \in \mathcal{A_0}$ such that $\mathbb{E}_F[y]-c &gt;0$ (the principal should have some reason for hiring the agent); $w$ must be continuous.</p>
<p>Bob's behavior is quite simple, given that Bob has all information. The set of actions $(F,c) \in \mathcal{A}$ Bob will consider are those which maximize $\mathbb{E}_F(y) - c.$<sup class="footnote-reference"><a href="#2">2</a></sup> We denote this by $\mathcal{A}^* (w | \mathcal{A}),$ and we denote by $V_A(w|A)$ the expected payoff of Bob given rational behavior. Alice's expected payoff is then</p>
<p>$$
V_P(w|\mathcal{A}) = \max_{(F,c) \in \mathcal{A}^*(w|\mathcal{A})} \mathbb{E}_F[y-w(y)],
$$</p>
<p>and Alice searches over expected payoffs as</p>
<p>$$
V_P(w) = \inf_{\mathcal{A} \supseteq \mathcal{A}_0} V_P(w|\mathcal{A}).
$$
We are interested in $w$ such that $V_P(w)$ is maximized.</p>
<h2>optimality in the zero-shot game</h2>
<p>Motivating example: $w(y) = \alpha y$ always guarantees the principal Alice positive worst-case payoff, for $\alpha \in [0,1]$. This analysis holds independently of the possible technology $\mathcal{A},$ due to the nontriviality assumption we impose on $\mathcal{A}_0.$</p>
<p>Proof: Rewrite $y - w(y)$ as $w(y)/\alpha - w(y) = \frac{1-\alpha}{\alpha}w(y).$ Lower bound $\mathbb{E}_F[w(y)]$ (the expected payment of Bob the agent) with $\mathbb{E}_F[w(y)] \geq \mathbb{E}_F[w(y)] - c = V_A(w|\mathcal{A})$, which is  $\geq V_A(w|\mathcal{A}_0)$ (because adding more actions to the agent can't decrease the optimal outcome given $\mathcal{A}_0$). Combining the two gives</p>
<p>$$\mathbb{E}_F[y-w(y)] \geq \frac{1-\alpha}{\alpha}\mathbb{E}_F[w(y)] \geq \frac{1-\alpha}{\alpha}V_A(w|\mathcal{A}_0),$$</p>
<p>which gives $V_P(w) \geq \frac{1-\alpha}{\alpha}V_A(w|\mathcal{A}_0).$ Given the nontrivality assumption $V_A(w|\mathcal{A}_0) &gt; 0,$ this means that this gives Alice a positive lower bound on the worst case outcome independent of the choice of technology $\mathcal{A}!$</p>
<p>Is there a sense in which linear contracts are "the best you can do?" Carroll shows that any contract $w(y)$ can be improved to a linear contract, even if $w(y)$ is pathological. The gist of the argument is as follows: consider the convex hull of the curve $w(y)$ that lies above the value $V_A(w|\mathcal{A}_0).$ Consider the $Q = (y',w(y'))$ point which minimizes $\mathbb{E}_F[y] - \mathbb{E}_F[w(y)].$ This is the worst case for Alice, the principal. $Q$ will typically be where $V_A(w|\mathcal{A}_0)$ intersects the left side of the convex hull. Note that the line parametrizing the intersecting boundary of this convex hull is itself a contract $w'(y)$ which dominates $w(y)!$ Repeating this process and considering some technical details gives you the optimality result.</p>
<img src="/images/carroll_fig1.png" alt="cfg1" width="550"/>
<p>The full technical details can be found the paper, and I will not discuss them now. However, I would like to discuss the generalization of this lemma to include more observables to the principal.</p>
<p>Let $z = (z_1, \ldots, z_k)$ range over a compact set $\mathcal{Z} \subseteq \mathbb{R}^k.$ Define a cost function $b: \mathbb{R}^k \to \mathbb{R}^+$ such that actions depend on $b:$ an action is then $(F,c)$ such that $F \in \Delta(\mathcal{Z})$ and $c \geq b(\mathbb{E}_F(z)).$ A contract is now a function $w: \mathcal{Z} \to \mathbb{R}^+.$ Changing the definitions of $\mathcal{A}_0, V_A$ appropriately etc., it turns out the optimally robust contract is <em>linear in the observables available to the principal.</em> Precisely, the optimal contract is of the form</p>
<p>$$w(z) = \alpha_1z_1 + \cdots + \alpha_kz_k + \beta$$</p>
<p>for real numbers $\alpha_i, \beta.$</p>
<h2>learnability</h2>
<p>It seems like the linear optimality result for robust contracts is pretty general and not too sensitive to assumptions: load-bearing here is that $\mathcal{Y}$ has a minimum that we normalize to be zero, some relaxed version of the nontrivality assumption, and that the risk associated with any particular action is quantifiable in a shared manner by both the principal and the agent.<sup class="footnote-reference"><a href="#3">3</a></sup></p>
<p>One obvious consideration: consider the possibility of unbounded risk to the principal (as suggested in <a href="https://alignmentproject.aisi.gov.uk/research-area/economic-theory-and-game-theory">UK AISI's Economics and Game Theory research agenda</a>). It is difficult to construct contracts that then robustly protect against these scenarios, even with partial information. What are the minimum viable assumptions necessary to get guarantees in this regime?</p>
<p>Another consideration that I am interested in: this feels very similar to classical bandit problems in RL. Heck, the agent is engaging in the optimal bandit policy given a set of lotteries! Unifying the two literatures (perhaps <a href="https://proceedings.neurips.cc/paper/2021/file/49ef08ad6e7f26d7f200e1b2b9e6e4ac-Paper.pdf">[KZ25]</a> is of interest) might tell us something interesting about certain classes of decision problems.</p>
<p>Also, learnable agents would (I think) perform better than static ones on a kind of mixed-objective performance metric! Perhaps one which mixes expected average and expected worst-case reward, with some weighting. Generally, intuitive restrictions &amp; extensions on this result are things I'm excited about.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>The majority of this post is a distillation of this paper. All credit to Gabriel Carroll.</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>$\mathcal{A}^* (w | \mathcal{A})$ is guaranteed to be nonempty by continuity and compactness.</p>
</div>
<div class="footnote-definition" id="3"><sup class="footnote-definition-label">3</sup>
<p>This one in particular has some philosophical implications.</p>
</div>

                        </div>
                    </article>
                    
                        <hr class="post-separator">
                    
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/2025-08-19/">Review | Pieces of the Action</a></h2>
                            <time datetime="2025-08-19">August 19, 2025</time>
                        </header>
                        <div class="post-content">
                            <p><em>nb: attempting a daily posting cadence. adjust quality priors accordingly</em></p>
<p>[1] Bush has quite a dim view of the institutional management of British science during WW2. Frequently, he points out that Churchill has too much influence over Cherwell (and it's Churchill's fault), he devotes an entire chapter to decrying the archetype of Geoffrey Pyke ("how to mitigate and excise tyros from an institution"), and his only interactions with Churchill were spats over the post-war sharing of nuclear secrets (which caused Churchill to ask FDR to fire him). In general, complaints are that it was overcomplicated, insufficiently meritocratic, and subject to the political whims of the executive. Britishers did not understand the importance of the "engineer." Of course, he quite likes Britishers on the whole, but there is a sense in which the British effort had negative polarity on exactly the qualities which made the OSRD so effective.</p>
<p>[2] What did make the OSRD effective? Autonomy, resources, collaboration with industry and academics, and a culture which made sure that issues were raised to the correct person, regardless of status. FDR never interfered with its runnings, even when they encompassed the Manhattan Project. Bush himself fielded suggestions on anti-submarine warfare from American hobbyists looking to contribute. Effective managers were essential—people who were well respected, deferred to authority, and could execute with little direction. Beyond that, it seems like Bush himself was essential, if only because of the sheer weight of the interpersonal relationships needed to be cultivated while working in Washington. The book itself is simply a long series of anecdotes involving important people, discussing their moods and motivations. Ultimately, this is how the world runs.</p>
<p>[3] He is proud of the development of the proximity fuze and the mass production of penicillin. Neither would have been possible without intense scientific research as well as the might of American industry being brought to bear. With regards to the modern day, I do believe that this is a lesson to never quite underestimate the potential state capacity of the American nation. Bush himself highlights that the pluralism of technological development in American peacetime is exactly what makes it so powerful during war—the USA can simply generate ideas and implement them at scale much more effectively than any other.</p>
<p>[4] The anecdotes are quite wonderful. I enjoyed his advice on teaching; his discussion of what it meant to be an "inventor"; his admiration of Harry Truman and those in the Roosevelt administration who, despite holding absurd economic views, were still good men; his promotion of steam-powered cars (!); his appreciation of "military men"; and many others. A reminder of a different time.</p>

                        </div>
                    </article>
                    
                        <hr class="post-separator">
                    
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/2025-08-18/">GHz momentum computing simulation #1</a></h2>
                            <time datetime="2025-08-18">August 18, 2025</time>
                        </header>
                        <div class="post-content">
                            <p><em>nb: attempting a daily posting cadence as weekly clearly doesn't work. adjust quality priors accordingly</em></p>
<p>Momentum computing is, as far as I can tell, a reversible computing paradigm which circumvents Landauer's limit by embedding the memory state transitions of some computing device in a physical system which equilibriates slower than the time it takes to do an individual bit-swap, so that the memory state transitions themselves can store information in their "instantaneous momenta" and subsequently perform bit-swaps with near-zero net work.<sup class="footnote-reference"><a href="#1">1</a></sup></p>
<p>In particular, one can construct toy theoretical energy potentials which implement a $\Delta W = 0$ Fredkin gate.<sup class="footnote-reference"><a href="#2">2</a></sup> Consider a particle $(x,p)$ in the 1D potential $V_B(x) = \alpha x^4 - \beta x^2.$ The two minimal states are located at $x = \pm \sqrt{\beta / 2\alpha},$ and as transitioning from the $x &lt; 0$ regime to the $x &gt;0$ regime is exponentially prohibitive in the value of $V(0),$ the system "stores" a bit $\{0,1\}$ depending on the sign of the particle's position.</p>
<p>Now imagine that $V_B$ encodes a thermal bath in which the particle $(x,p)$ is embedded in, and assume that the particle's motion follows harmonic oscillation in the absence of external influence. When the bath is active, the particle's potential is described by $V_B.$ But when the bath is disengaged, the particle behaves according to $V_H(x) = kx^2/2,$ which induces a trajectory $x(t) = A \cos(t \sqrt{k/m} + \phi),$ which is periodic in time $\tau = 2\pi \sqrt{m/k}.$ Therefore, disengaging the bath for time $\tau/2$ swaps the sign of the particle's position, effectively performing a bit-swap.</p>
<p>This theoretical "bit-swap" comes at no work cost because there is no change in potential energy from time $0$ to $\tau/2.$<sup class="footnote-reference"><a href="#3">3</a></sup> However, any physical implementation of this concept must contend with the fact that changing the potentials in a physical system requires energy to be expended, likely in an inefficient manner. How does one get around this? Superconductors!</p>
<h2>gradiometric flux logic cells</h2>
<p>The theoretical guarantees above require complete &amp; efficient decoupling of the system from the bath. You can get similar results by simply ensuring that the relevant computational timescale is significantly smaller than the energy flux rate between the system and its bath, so that "from the perspective of the computation" there is no coupling.</p>
<p><a href="http://arxiv.org/abs/2202.07122">[RC22]</a> chooses to implement such a system with <em>gradiometric flux logic cells</em>, a kind of circuit utilizing Josephson junctions designed particularly to withstand global magnetic noise fluctuations [I do not really understand GFLCs very well, that will be a topic for another day's post].</p>
<img src="/images/gradiometric-flux-logic-cell.png" alt="GFLC" width="400"/>
<p>With suitable assumptions &amp; parametrizations [such will be the subject of yet another day's post], the GFLCs follow "significantly underdamped Langevin dynamics", which can be described with the following equation:
$$
dv' = -\lambda v'dt' - \theta \partial_{x'}U' + \nu r(t)\sqrt{2dt'}
$$
where the potential $U$ evolves according to
$$
U'(t') = (\phi-\phi_x(t'))^2/2  + \gamma(\phi_{dc} - \phi_{xdc}(t'))^2/2 + \beta \cos \phi \cos (\phi_{dc}/2) + \delta \beta \sin \phi \sin (\phi_{dc}/2)
$$
where $x' = (\phi, \phi_{dc}), v' = (\dot{\phi}, \dot{\phi_{dc}})$, $\phi = (\phi_1 + \phi_2)/2 - \pi,$ $\phi_{dc} = (\phi_2 - \phi_1),$ and $\phi_1, \phi_2$ are the phases of the individual Josephson junctions $I_{c1}, I_{c2}$ in the above figure [I think]. $\phi_{x} = 2\pi \psi_x / \bf{\Phi}_0 - \pi$ and $\phi_{xdc} = 2\pi \psi_{xdc} / \bf{\Phi}_0$ are functions of the external magnetic fluxes $\psi_x, \psi_{xdc}$ applied to the circuit.</p>
<p>The details of this are very interesting, still confusing to me, and this is by no means an exhaustive parametrization of the underlying models. However, below (Fig. 2) showcases that varying $\phi$ and $\phi_{dc}$, the sum and difference of the Josephson phase parameters, recovers the potential geometry associated with costless bitswaps.</p>
<img src="/images/gflc-2.png" alt="GFLC" width="400"/>
<h2>further considerations</h2>
<ul>
<li>I really want to understand the interface between the theoretical dynamics and the physical implementation better. Why is this theory so substrate independent? Why does it matter that our memory state transitions are modeled by CTHMCs instead of CTMCs? Why are we using superconductors?</li>
<li>How do we actually get efficient circuit modeling of the kind described here? I couldn't readily find a Github repository associated with the paper, so I want to write my own library and replicate their results. They find that the efficiency of their circuits are largely dependent on "circuit hyperparameters", and it would be interesting to investigate their structure.</li>
<li>Benchmarks for algorithms that can be implemented with momentum computing and with typical CMOS/transistor logic, and developing simulations that can accurately predict efficiency differences. Still not sure how to think about this! Will absolutely be the topic of a later post.</li>
<li>Fermi estimates of all the physical quantities at play here. What is "one Landauer" at STP? How much does it cost to make a gradiometric flux logic cell? Etc. Etc.</li>
</ul>
<p>All credit goes to the coauthors of the two papers cited in this post.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>This is probably wrong and definitely imprecise, but it reflects my current level of understanding.</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>Setting taken from <a href="http://arxiv.org/abs/2010.01152">[RWBC21]</a>.</p>
</div>
<div class="footnote-definition" id="3"><sup class="footnote-definition-label">3</sup>
<p>Here we describe the one-dimensional case for intuition, but the paper details the Fredkin gate implementation with this method, which requires three-dimensional potentials to encode $101 \leftrightarrow 110$ and No Change otherwise.</p>
</div>

                        </div>
                    </article>
                    
                        <hr class="post-separator">
                    
                
                    <article class="post" data-good="false">
                        <header>
                            <h2><a href="https://yudhister.me/rfc-761/">Notes on RFC 761</a></h2>
                            <time datetime="2025-06-07">June 07, 2025</time>
                        </header>
                        <div class="post-content">
                            <blockquote>
<p>TCP implementations should follow a general principle of robustness: be conservative in what you do, be liberal in what you accept from others.</p>
</blockquote>
<p>The original TCP specification is explicitly designed to be agnostic to IP implementation. It's only supposed to handle byte transfer from application to application, not the specifics of packet delivery between hosts. In practice, this ideal is unattainable<sup class="footnote-reference"><a href="#1">1</a></sup>, but it points at a deep truth about healthy integration of parts in systems.</p>
<p>Modularity is a natural consequence of system complexification. Internal bottlenecks on information transfer necessitate internal specialization<sup class="footnote-reference"><a href="#2">2</a></sup>. Dually, effective modularity requires partwise efficiency: judicious outputs and robustness to inputs, through either filtration or error-correction.</p>
<p>Cells have well-defined outputs and boundaries which protect them from harmful inputs. Organs as well. Intuitively, the "conservative output, liberal input" principle could be reformulated as a "specific function, high survivability" dogma which we find exhibited in biological systems.</p>
<p>Admittedly, TCP has more in common with the blood-brain barrier than it does with the liver. But the Internet is special in that the design of transportation organs is centralized while the design of substantive organs is not, and as a result boundary-manufacture is a centralized process. Insofar as the success of biological systems is to be attributed to organ-organ boundaries, those same properties may be reflected in TCP.</p>
<p>As the Internet scaled to tens of thousands of simultaneous hosts operating on the same network, the RFC 761 implementation could no longer support reasonable host to host communication without congestion collapse, requiring updates to the default TCP. Yet modern TCPs are backwards compatible with TCPs from 1980, in part because the abstraction was so well-designed.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>One example is TCP's checksum operation: it relies on IP address structure, so it had to be slightly modified to accomodate IPv6.</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>Eukaryotic protein connectomes have higher EI than prokaryotic ones. As arbitrary protein-protein interaction takes more energy, efficient configurations will exhibit clustering of function.</p>
</div>

                        </div>
                    </article>
                    
                

                
                <nav class="pagination">
                    
                        <a class="previous" href="https://yudhister.me/notes/page/5/">‹ Previous</a>
                    
                    <span class="page-number">Page 6 of 11</span>
                    
                        <a class="next" href="https://yudhister.me/notes/page/7/">Next ›</a>
                    
                </nav>

            
        
    </main>
</body>
</html>
